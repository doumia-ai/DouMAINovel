"""OpenAI / Zhipu(BigModel) æœ€ç»ˆå…¼å®¹å®¢æˆ·ç«¯"""
import json
from typing import Any, AsyncGenerator, Dict, Optional

from app.logger import get_logger
from .base_client import BaseAIClient

logger = get_logger(__name__)


class OpenAIClient(BaseAIClient):
    """OpenAI API å®¢æˆ·ç«¯ï¼ˆå·¥ç¨‹çº§å…¼å®¹æ™ºè°± BigModelï¼‰"""

    # ======================
    # åŸºç¡€åˆ¤æ–­
    # ======================

    def _is_zhipu_api(self) -> bool:
        return "bigmodel.cn" in self.base_url

    def _build_headers(self) -> Dict[str, str]:
        return {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }

    # ======================
    # Payload æ„é€ 
    # ======================

    def _build_payload(
        self,
        messages: list,
        model: str,
        temperature: float,
        max_tokens: int,
        tools: Optional[list] = None,
        tool_choice: Optional[str] = None,
        stream: bool = False,
    ) -> Dict[str, Any]:

        is_zhipu = self._is_zhipu_api()

        # ---- 1ï¸âƒ£ messages æ¸…æ´—ï¼ˆæ™ºè°±å¼ºåˆ¶è¦æ±‚ï¼‰----
        clean_messages = [
            m for m in messages
            if m.get("content") and str(m["content"]).strip()
        ]

        # ---- 2ï¸âƒ£ temperature ä¿®æ­£ï¼ˆæ™ºè°±ä¸å…è®¸ <=0ï¼‰----
        if is_zhipu and temperature <= 0:
            temperature = 0.1
            logger.debug("ğŸ”§ Zhipu: temperature è°ƒæ•´ä¸º 0.1")

        payload: Dict[str, Any] = {
            "model": model,
            "messages": clean_messages,
            "temperature": temperature,
        }

        # ---- 3ï¸âƒ£ max_tokens ----
        if is_zhipu:
            # GLM-4.5 ç³»åˆ—æ”¯æŒè¾ƒå¤§çš„è¾“å‡ºé•¿åº¦ï¼Œè®¾ç½®åˆç†å€¼é¿å…è¢«é»˜è®¤å€¼æˆªæ–­
            payload["max_tokens"] = min(max_tokens, 8192)
        else:
            payload["max_tokens"] = max_tokens

        # ---- 4ï¸âƒ£ streamï¼ˆæ™ºè°±ä¸æ”¯æŒ OpenAI SSEï¼‰----
        if stream and not is_zhipu:
            payload["stream"] = True

        # ---- 5ï¸âƒ£ toolsï¼ˆæ™ºè°±å·¥ç¨‹ä¸Šé»˜è®¤ç¦ç”¨ï¼‰----
        if tools and not is_zhipu:
            cleaned = []
            for t in tools:
                tc = t.copy()
                if "function" in tc and "parameters" in tc["function"]:
                    tc["function"]["parameters"] = {
                        k: v
                        for k, v in tc["function"]["parameters"].items()
                        if k != "$schema"
                    }
                cleaned.append(tc)

            payload["tools"] = cleaned
            if tool_choice:
                payload["tool_choice"] = tool_choice

        return payload

    # ======================
    # éæµå¼
    # ======================

    async def chat_completion(
        self,
        messages: list,
        model: str,
        temperature: float,
        max_tokens: int,
        tools: Optional[list] = None,
        tool_choice: Optional[str] = None,
    ) -> Dict[str, Any]:

        payload = self._build_payload(
            messages, model, temperature, max_tokens, tools, tool_choice
        )

        logger.debug(
            f"ğŸ“¤ ChatCompletion Payload:\n{json.dumps(payload, ensure_ascii=False, indent=2)}"
        )

        data = await self._request_with_retry("POST", "/chat/completions", payload)

        logger.debug(
            f"ğŸ“¥ ChatCompletion Response:\n{json.dumps(data, ensure_ascii=False, indent=2)}"
        )

        choices = data.get("choices", [])
        if not choices:
            raise ValueError("API è¿”å›ç©º choices")

        message = choices[0].get("message", {})
        finish_reason = choices[0].get("finish_reason")

        # æ£€æµ‹æ˜¯å¦å› é•¿åº¦é™åˆ¶è¢«æˆªæ–­
        if finish_reason == "length":
            logger.warning(f"âš ï¸ APIå“åº”å› é•¿åº¦é™åˆ¶è¢«æˆªæ–­ (finish_reason=length)ï¼Œå¯èƒ½å¯¼è‡´JSONä¸å®Œæ•´")

        return {
            "content": message.get("content", ""),
            "tool_calls": message.get("tool_calls"),
            "finish_reason": finish_reason,
        }

    # ======================
    # æµå¼
    # ======================

    async def chat_completion_stream(
        self,
        messages: list,
        model: str,
        temperature: float,
        max_tokens: int,
        tools: Optional[list] = None,
        tool_choice: Optional[str] = None,
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        OpenAI: åŸç”Ÿ SSE æµå¼
        Zhipu: è‡ªåŠ¨é™çº§ä¸ºéæµå¼ï¼ˆå·¥ç¨‹ç¨³å®šï¼‰
        """

        # ---- ğŸš« æ™ºè°±ç›´æ¥é™çº§ ----
        if self._is_zhipu_api():
            logger.warning("âš ï¸ Zhipu ä¸æ”¯æŒ OpenAI é£æ ¼ streamï¼Œå·²è‡ªåŠ¨é™çº§ä¸ºéæµå¼")
            result = await self.chat_completion(
                messages, model, temperature, max_tokens, tools, tool_choice
            )
            yield {"content": result["content"], "done": True}
            return

        # ---- OpenAI æ­£å¸¸æµå¼ ----
        payload = self._build_payload(
            messages,
            model,
            temperature,
            max_tokens,
            tools,
            tool_choice,
            stream=True,
        )

        tool_calls_buffer = {}

        try:
            async with await self._request_with_retry(
                "POST", "/chat/completions", payload, stream=True
            ) as response:
                response.raise_for_status()

                async for line in response.aiter_lines():
                    if not line.startswith("data: "):
                        continue

                    data_str = line[6:]
                    if data_str.strip() == "[DONE]":
                        if tool_calls_buffer:
                            yield {
                                "tool_calls": list(tool_calls_buffer.values()),
                                "done": True,
                            }
                        yield {"done": True}
                        break

                    try:
                        data = json.loads(data_str)
                    except json.JSONDecodeError:
                        continue

                    choices = data.get("choices", [])
                    if not choices:
                        continue

                    delta = choices[0].get("delta", {})

                    # æ–‡æœ¬
                    content = delta.get("content")
                    if content:
                        yield {"content": content}

                    # å·¥å…·è°ƒç”¨
                    tc_list = delta.get("tool_calls")
                    if tc_list:
                        for tc in tc_list:
                            index = tc.get("index", 0)
                            if index not in tool_calls_buffer:
                                tool_calls_buffer[index] = tc
                            else:
                                existing = tool_calls_buffer[index]
                                if (
                                    "function" in tc
                                    and "function" in existing
                                    and tc["function"].get("arguments")
                                ):
                                    existing["function"]["arguments"] += tc["function"]["arguments"]

        except Exception as e:
            logger.error(f"æµå¼è¯·æ±‚å‡ºé”™: {str(e)}")
            raise